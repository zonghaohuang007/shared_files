#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import print_function

import argparse
import os
import random

import torch
import torchvision
import torch.backends.cudnn as cudnn
import torch.nn.parallel
import torch.utils.data as data
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from scipy.stats import ttest_rel

from model import ResNet18
from tools import *


SOURCE_CLASS = 0
TARGET_CLASS = 1
POISON_NUM = 5000   # namely, the poison rate is 10%
CRAFT_ITERS = 250
RETRAIN_ITERS = 50
TRAIN_EPOCHS = 40
EPS = 16. / 255
DATASET = 'CIFAR10'
PATCH_SIZE = 8
IMAGE_SIZE = 32
CLASS_NUM = 10
BETA = 2.0


parser = argparse.ArgumentParser(description='PyTorch CIFAR-10')

parser.add_argument('-m', '--num_img', default=1000, type=int, metavar='N',
                    help='number of images for testing (default: 100)')

parser.add_argument('--margin', default=0.25, type=float,
                    help='the margin in the pairwise T-test')
parser.add_argument('--seed', default=666, type=int, help='random seed')

args = parser.parse_args()


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def get_model():
    if DATASET == 'CIFAR10' or DATASET == 'GTSRB' or  DATASET == 'CIFAR100':
        model = ResNet18(CLASS_NUM).to(device)
    return model


class Deltaset(torch.utils.data.Dataset):
    def __init__(self, dataset, delta, t_label):
        self.dataset = dataset
        self.delta = delta
        self.t_label = t_label

    def __getitem__(self, idx):
        (img, target) = self.dataset[idx]
        return (img + self.delta[idx], target)

    def __len__(self):
        return len(self.dataset)


def patch_source(trainset, target_label, random_patch=True):
    trigger = torch.Tensor([[0, 0, 1], [0, 1, 0], [1, 0, 1]])
    patch = trigger.repeat((3, 1, 1))
    resize = torchvision.transforms.Resize((PATCH_SIZE))
    patch = resize(patch)
    source_delta = []
    for idx, (source_img, label) in enumerate(trainset):
        if random_patch:
            patch_x = random.randrange(0, source_img.shape[1] - patch.shape[1] + 1)
            patch_y = random.randrange(0, source_img.shape[2] - patch.shape[2] + 1)
        else:
            patch_x = source_img.shape[1] - patch.shape[1]
            patch_y = source_img.shape[2] - patch.shape[2]

        delta_slice = torch.zeros_like(source_img).squeeze(0)
        diff_patch = patch - source_img[:, patch_x: patch_x + patch.shape[1], patch_y: patch_y + patch.shape[2]]
        delta_slice[:, patch_x: patch_x + patch.shape[1], patch_y: patch_y + patch.shape[2]] = diff_patch
        source_delta.append(delta_slice.cpu())
    trainset = Deltaset(trainset, source_delta, target_label)
    return trainset


def main():

    # load poisoned model
    poisoned_model = get_model()
    ckpt_dir = './Models/ResNet18_{}_dis_{}_{}_{}_{}_{}_{}.pth'.format(DATASET, BETA, POISON_NUM, PATCH_SIZE, CLASS_NUM, SOURCE_CLASS, TARGET_CLASS)
    poisoned_model.load_state_dict(torch.load(ckpt_dir), strict=True)
    poisoned_model.eval()

    # load clean model
    clean_model = get_model()
    ckpt_dir = './Models/ResNet18_{}.pth'.format(DATASET)
    clean_model.load_state_dict(torch.load(ckpt_dir), strict=True)
    clean_model.eval()
    
    # load dataset
    clean_dataset = torchvision.datasets.CIFAR10(
            root='/usr/project/xtmp/zh127/data', train=False, download=True, transform=torchvision.transforms.ToTensor(),
        )

    posioned_dataset = patch_source(clean_dataset, TARGET_CLASS)

    clean_data_loader = torch.utils.data.DataLoader(clean_dataset, batch_size=1, drop_last=False, shuffle=False)

    # keep test data that are correctly classified by the poisoned model
    kept_idx = []
    for idx, (inputs, targets) in enumerate(clean_data_loader):
        inputs, targets = inputs.cuda(), targets.cuda()
        outputs = clean_model(inputs)
        # print(outputs)
        outputs = torch.argmax(outputs, dim=1)[0]
        if outputs == targets[0]:
            kept_idx.append(idx)

    print(len(kept_idx)/len(clean_dataset))
    random.shuffle(kept_idx)

    clean_dataset = [clean_dataset[i] for i in kept_idx]
    poisoned_dataset = [posioned_dataset[i] for i in kept_idx]

    # use num_img test data in detection
    # clean_dataset= clean_dataset[:args.num_img]
    # poisoned_dataset = poisoned_dataset[:args.num_img]

    clean_data_loader = torch.utils.data.DataLoader(clean_dataset, batch_size=1, drop_last=False, shuffle=False)
    poisoned_data_loader = torch.utils.data.DataLoader(poisoned_dataset, batch_size=1, drop_last=False, shuffle=False)

    output_clean = test(clean_data_loader, clean_model) 
    output_poisoned = test(poisoned_data_loader, poisoned_model)

    print(np.mean(output_clean))
    print(np.mean(output_poisoned))

    T_test = ttest_rel(output_poisoned + args.margin, output_clean, alternative='less')

    # output p value
    print(T_test[1])


def test(testloader, model, use_cuda=True):
    model.eval()
    return_output = []
    for _, (inputs, targets) in enumerate(testloader):
        if use_cuda:
            inputs, targets = inputs.cuda(), targets.cuda()

        with torch.no_grad():
            outputs = torch.nn.functional.softmax(model(inputs), dim=1)[0][targets[0]]
            return_output.append(outputs.cpu().detach().numpy())

    return np.array(return_output)


if __name__ == '__main__':
    main()
